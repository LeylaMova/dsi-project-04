{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../data/indeed-scraped-job-postings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)\n",
    "df.drop(['salary'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "107762.69581280788"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean = df.parsed_salary.mean()\n",
    "mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['above_107k'] = df.parsed_salary.apply(lambda x: 1 if x > mean else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    217\n",
       "1    189\n",
       "Name: above_107k, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['above_107k'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.summary = df.summary.str.replace((',|/|\\(|\\)'),(' ')).str.strip().str.lower()\n",
    "df.title = df.title.str.replace((',|/|\\(|\\)'),(' ')).str.strip().str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ds_tools = 'R SQL Python ML NLP C Algorithms Algorithm Algo MYSQL \\\n",
    "CNUP JS Java Erlang Impala Geospatial Hadoop SAS Java Hive \\\n",
    "Matlab Pig UNIX Linux Ruby SPSS Tableau Excel AWS \\\n",
    "SVP API Spark Scala awk Cassandra JavaScript Storm Cloud Agile'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ds_tools = ds_tools.lower().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "pattern = re.compile(r'\\b(' + r'|'.join(ds_tools) + r')\\b\\s*')\n",
    "\n",
    "df['language'] = df['summary'].str.findall(pattern)\n",
    "df['language_t'] = df['title'].str.findall(pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "level = ['senior','sr.','junior','jr.','lead','vp','vice president', 'avp','assistant',\n",
    "         'asst.','director','dir','staff','master','masters','postdoc','manager','mid-level',\n",
    "         'postdoctoral','post-doctoral','deputy','associate','entry level',' 1 ',' 2 ',' 3 ',\n",
    "         ' iv ',' iii ',' ii ',' i ','phd','fellow','head','supervisory','snr','chief',\n",
    "         'specialist','ms','consultant','consultants']\n",
    "\n",
    "pattern = '(%s)' % '|'.join(level)\n",
    "df['levels'] = df['title'].str.findall(pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['', 'senior', 'assistant', 'specialist', 'manager',\n",
       "       'assistant-manager', 'sr.', 'postdoc', 'entry level', 'lead',\n",
       "       'director', 'staff', 'master', 'ms', 'associate', 'sr.-consultant',\n",
       "       'ms-phd', 'mid-level', 'senior-manager', 'vp', 'avp', ' 3 ',\n",
       "       'senior-director', 'post-doctoral', ' iii ', 'deputy-director',\n",
       "       'ms-manager', 'assistant- i ', 'junior', 'postdoc-fellow',\n",
       "       'senior-staff-assistant', 'senior-lead', 'postdoc-associate',\n",
       "       'senior-ms', 'jr.', 'manager-ms', 'asst.-director', 'chief', 'phd',\n",
       "       'junior-mid-level', 'phd-ms', ' iv ', ' ii ',\n",
       "       'senior-staff-director', 'specialist- i ', 'head', 'vice president',\n",
       "       'supervisory', 'dir', 'snr'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['levels'] = df['levels'].apply(lambda x: '-'.join(x))\n",
    "df['levels'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['levels'] = np.where(df['levels'] =='sr.', 'senior', df['levels'])\n",
    "df['levels'] = np.where(df['levels'] =='jr.', 'junior', df['levels'])\n",
    "df['levels'] = np.where(df['levels'] =='post-doctoral','postdoc', df['levels'])\n",
    "df['levels'] = np.where(df['levels'] =='entry level', 'assistant', df['levels'])\n",
    "df['levels'] = np.where(df['levels'] =='avp', 'assistant', df['levels'])\n",
    "df['levels'] = np.where(df['levels'] ==' 3 ', 'junior', df['levels'])\n",
    "df['levels'] = np.where(df['levels'] ==' iv ', 'senior', df['levels'])\n",
    "df['levels'] = np.where(df['levels'] =='assistant- i ', 'assistant', df['levels'])\n",
    "df['levels'] = np.where(df['levels'] =='specialist- i ', 'assistant', df['levels'])\n",
    "df['levels'] = np.where(df['levels'] ==' ii ', 'junior', df['levels'])\n",
    "df['levels'] = np.where(df['levels'] ==' iii ', 'junior', df['levels'])\n",
    "df['levels'] = np.where(df['levels'] =='mid-level', 'junior', df['levels'])\n",
    "df['levels'] = np.where(df['levels'] =='vice president', 'vp', df['levels'])\n",
    "df['levels'] = np.where(df['levels'] =='dir', 'director', df['levels'])\n",
    "df['levels'] = np.where(df['levels'] =='asst.-director', 'assistant', df['levels'])\n",
    "df['levels'] = np.where(df['levels'] =='snr', 'senior', df['levels'])\n",
    "df['levels'] = np.where(df['levels'] =='ms', 'master', df['levels'])\n",
    "df['levels'] = np.where(df['levels'] =='ms-phd', 'master-phd', df['levels'])\n",
    "df['levels'] = np.where(df['levels'] =='phd-ms', 'master-phd', df['levels'])\n",
    "df['levels'] = np.where(df['levels'] =='ms-manager', 'manager', df['levels'])\n",
    "df['levels'] = np.where(df['levels'] =='manager-ms', 'manager', df['levels'])\n",
    "df['levels'] = np.where(df['levels'] =='senior-ms', 'senior', df['levels'])\n",
    "df['levels'] = np.where(df['levels'] =='sr.-consultant', 'senior', df['levels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['senior'] = df[\n",
    "    'levels'].apply(lambda x: 1 if re.findall('senior',x) else 0)\n",
    "df['junior'] = df[\n",
    "    'levels'].apply(lambda x: 1 if re.findall('junior',x) else 0)\n",
    "df['manager'] = df[\n",
    "    'levels'].apply(lambda x: 1 if re.findall('manager',x) else 0)\n",
    "df['assistant'] = df[\n",
    "    'levels'].apply(lambda x: 1 if re.findall('assistant',x) else 0)\n",
    "df['director'] = df[\n",
    "    'levels'].apply(lambda x: 1 if re.findall('director',x) else 0)\n",
    "df['associate'] = df[\n",
    "    'levels'].apply(lambda x: 1 if re.findall('associate',x) else 0)\n",
    "df['vp'] = df[\n",
    "    'levels'].apply(lambda x: 1 if re.findall('vp',x) else 0)\n",
    "df['master'] = df[\n",
    "    'levels'].apply(lambda x: 1 if re.findall('master',x) else 0)\n",
    "df['phd'] = df[\n",
    "    'levels'].apply(lambda x: 1 if re.findall('phd',x) else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "patterns = ['big.data','bi data','data scien+','analy+','statist+',\n",
    "            'enginee+','deep l+','machine l+','developer','programmer',\n",
    "            'op+','devop+','developm+','gs','natural language processing','nlp','full stack']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pattern = '(%s)' % '|'.join(patterns)\n",
    "df['words'] = df['summary'].str.findall(pattern)\n",
    "df['words_t'] = df['title'].str.findall(pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['words'] = df['words'] + df['words_t']\n",
    "df['language'] = df['language'] + df['language_t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['words'] = df['language'] + df['words']\n",
    "df['words'] = df['words'].str.join(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.drop(['language_t','words_t','language'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "big_data = ['big.data','bi data']\n",
    "pattern = '(%s)' % '|'.join(big_data)\n",
    "\n",
    "df['big_data'] = df['words'].apply(lambda x: 1 if re.findall(pattern,x) else 0)\n",
    "df['data_scientist'] = df['words'].apply(lambda x: 1 if re.findall('data scien+',x) else 0)\n",
    "df['analyst'] = df['words'].apply(lambda x: 1 if re.findall('analy+',x) else 0)\n",
    "df['statistic'] = df['words'].apply(lambda x: 1 if re.findall('statist+',x) else 0)\n",
    "df['engineer'] = df['words'].apply(lambda x: 1 if re.findall('enginee+',x) else 0)\n",
    "df['deep_learning'] = df['words'].apply(lambda x: 1 if re.findall('deep l+',x) else 0)\n",
    "df['machine_learning'] = df[\n",
    "    'words'].apply(lambda x: 1 if re.findall('machine l+',x) else 0)\n",
    "df['developer'] = df[\n",
    "    'words'].apply(lambda x: 1 if re.findall('developer',x) else 0)\n",
    "df['programmer'] = df[\n",
    "    'words'].apply(lambda x: 1 if re.findall('programmer',x) else 0)\n",
    "df['operations'] = df[\n",
    "    'words'].apply(lambda x: 1 if re.findall('op+',x) else 0)\n",
    "df['devops'] = df[\n",
    "    'words'].apply(lambda x: 1 if re.findall('devop+',x) else 0)\n",
    "df['development'] = df[\n",
    "    'words'].apply(lambda x: 1 if re.findall('developm+',x) else 0)\n",
    "df['government'] = df[\n",
    "    'words'].apply(lambda x: 1 if re.findall('gs',x) else 0)\n",
    "df['nlp'] = df[\n",
    "    'words'].apply(lambda x: 1 if re.findall('natural language processing|nlp',x) else 0)\n",
    "df['full_stack'] = df[\n",
    "    'words'].apply(lambda x: 1 if re.findall('full stack',x) else 0)\n",
    "df['r'] = df[\n",
    "    'words'].apply(lambda x: 1 if re.findall('r',x) else 0)\n",
    "df['sql'] = df[\n",
    "    'words'].apply(lambda x: 1 if re.findall('sql',x) else 0)\n",
    "df['python'] = df[\n",
    "    'words'].apply(lambda x: 1 if re.findall('python',x) else 0)\n",
    "df['ml'] = df[\n",
    "    'words'].apply(lambda x: 1 if re.findall('ml',x) else 0)\n",
    "df['c++'] = df[\n",
    "    'words'].apply(lambda x: 1 if re.findall('c',x) else 0)\n",
    "df['algorithm'] = df[\n",
    "    'words'].apply(lambda x: 1 if re.findall('algorithms|algorithm|algo',x) else 0)\n",
    "df['mysql'] = df[\n",
    "    'words'].apply(lambda x: 1 if re.findall('mysql',x) else 0)\n",
    "df['javascript'] = df[\n",
    "    'words'].apply(lambda x: 1 if re.findall('js|javascript',x) else 0)\n",
    "df['erlang'] = df[\n",
    "    'words'].apply(lambda x: 1 if re.findall('erlang',x) else 0)\n",
    "df['impala'] = df[\n",
    "    'words'].apply(lambda x: 1 if re.findall('impala',x) else 0)\n",
    "df['geospatial'] = df[\n",
    "    'words'].apply(lambda x: 1 if re.findall('geospatial',x) else 0)\n",
    "df['hadoop'] = df[\n",
    "    'words'].apply(lambda x: 1 if re.findall('hadoop',x) else 0)\n",
    "df['sas'] = df[\n",
    "    'words'].apply(lambda x: 1 if re.findall('sas',x) else 0)\n",
    "df['java'] = df[\n",
    "    'words'].apply(lambda x: 1 if re.findall('java',x) else 0)\n",
    "df['hive'] = df[\n",
    "    'words'].apply(lambda x: 1 if re.findall('hive',x) else 0)\n",
    "df['matlab'] = df[\n",
    "    'words'].apply(lambda x: 1 if re.findall('matlab',x) else 0)\n",
    "df['pig'] = df[\n",
    "    'words'].apply(lambda x: 1 if re.findall('pig',x) else 0)\n",
    "df['spss'] = df[\n",
    "    'words'].apply(lambda x: 1 if re.findall('spss',x) else 0)\n",
    "df['cloud'] = df[\n",
    "    'words'].apply(lambda x: 1 if re.findall('cloud',x) else 0)\n",
    "df['scala'] = df[\n",
    "    'words'].apply(lambda x: 1 if re.findall('scala',x) else 0)\n",
    "df['unix'] = df[\n",
    "    'words'].apply(lambda x: 1 if re.findall('unix',x) else 0)\n",
    "df['cnup'] = df[\n",
    "    'words'].apply(lambda x: 1 if re.findall('cnup',x) else 0)\n",
    "df['aws'] = df[\n",
    "    'words'].apply(lambda x: 1 if re.findall('aws',x) else 0)\n",
    "df['spark'] = df[\n",
    "    'words'].apply(lambda x: 1 if re.findall('spark',x) else 0)\n",
    "df['cassandra'] = df[\n",
    "    'words'].apply(lambda x: 1 if re.findall('cassandra',x) else 0)\n",
    "df['svp'] = df[\n",
    "    'words'].apply(lambda x: 1 if re.findall('svp',x) else 0)\n",
    "df['tableau'] = df[\n",
    "    'words'].apply(lambda x: 1 if re.findall('tableau',x) else 0)\n",
    "df['api'] = df[\n",
    "    'words'].apply(lambda x: 1 if re.findall('api',x) else 0)\n",
    "df['linux'] = df[\n",
    "    'words'].apply(lambda x: 1 if re.findall('linux',x) else 0)\n",
    "df['excel'] = df[\n",
    "    'words'].apply(lambda x: 1 if re.findall('excel',x) else 0)\n",
    "df['ruby'] = df[\n",
    "    'words'].apply(lambda x: 1 if re.findall('ruby',x) else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "city_df = pd.get_dummies(df['city'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Baseline\n",
    "\n",
    "base_accuracy = 1.0 - df['above_107k'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "level_df = df[['senior','junior','manager','assistant','director',\n",
    "               'associate','vp','master','phd','above_107k']]\n",
    "key_words = ['big_data','data_scientist','analyst','statistic','engineer','deep_learning',\n",
    "              'machine_learning','developer','programmer','operations','devops','development',\n",
    "              'government','nlp','full_stack','r','sql','python','ml','c++','algorithm','mysql',\n",
    "              'javascript','erlang','impala','geospatial','hadoop','sas','java','hive','matlab',\n",
    "              'pig','spss','cloud','scala','unix','cnup','aws','spark','cassandra','svp',\n",
    "              'tableau','api','linux','excel','ruby']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = df['above_107k']\n",
    "X = city_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.580944\n",
      "         Iterations: 35\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:             above_107k   No. Observations:                  406\n",
      "Model:                          Logit   Df Residuals:                      388\n",
      "Method:                           MLE   Df Model:                           17\n",
      "Date:                Mon, 16 Jan 2017   Pseudo R-squ.:                  0.1590\n",
      "Time:                        21:55:37   Log-Likelihood:                -235.86\n",
      "converged:                      False   LL-Null:                       -280.45\n",
      "                                        LLR p-value:                 8.617e-12\n",
      "=================================================================================\n",
      "                    coef    std err          z      P>|z|      [95.0% Conf. Int.]\n",
      "---------------------------------------------------------------------------------\n",
      "Atlanta          -1.3218      0.563     -2.349      0.019        -2.425    -0.219\n",
      "Austin           -0.2877      0.764     -0.377      0.706        -1.785     1.209\n",
      "Boston            0.3878      0.297      1.305      0.192        -0.195     0.970\n",
      "Chicago           0.2364      0.345      0.684      0.494        -0.441     0.913\n",
      "Dallas           -0.6931      0.612     -1.132      0.258        -1.893     0.507\n",
      "Denver           -2.0149      0.753     -2.677      0.007        -3.490    -0.539\n",
      "Houston         -13.9867    363.115     -0.039      0.969      -725.679   697.706\n",
      "Los+Angeles      -0.0870      0.417     -0.208      0.835        -0.905     0.731\n",
      "Miami           -24.4518   8.33e+04     -0.000      1.000     -1.63e+05  1.63e+05\n",
      "New+York         -0.3973      0.202     -1.967      0.049        -0.793    -0.001\n",
      "Palo+Alto         0.8650      0.421      2.052      0.040         0.039     1.691\n",
      "Philadelphia      0.5596      0.627      0.893      0.372        -0.669     1.788\n",
      "Phoenix         -24.4518   8.33e+04     -0.000      1.000     -1.63e+05  1.63e+05\n",
      "Pittsburgh      -13.9867    363.115     -0.039      0.969      -725.679   697.706\n",
      "Portland        -19.1517   1.44e+04     -0.001      0.999     -2.83e+04  2.82e+04\n",
      "San+Diego        -0.4055      0.645     -0.628      0.530        -1.671     0.860\n",
      "San+Francisco     1.3083      0.356      3.671      0.000         0.610     2.007\n",
      "Seattle           0.1054      0.459      0.229      0.819        -0.795     1.006\n",
      "=================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Leyla/anaconda/lib/python2.7/site-packages/statsmodels/base/model.py:466: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "logit_model = sm.Logit(y,X)\n",
    "result=logit_model.fit()\n",
    "print result.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Atlanta          2.666667e-01\n",
      "Austin           7.500000e-01\n",
      "Boston           1.473684e+00\n",
      "Chicago          1.266667e+00\n",
      "Dallas           5.000000e-01\n",
      "Denver           1.333333e-01\n",
      "Houston          8.426937e-07\n",
      "Los+Angeles      9.166667e-01\n",
      "Miami            2.402700e-11\n",
      "New+York         6.721311e-01\n",
      "Palo+Alto        2.375000e+00\n",
      "Philadelphia     1.750000e+00\n",
      "Phoenix          2.402700e-11\n",
      "Pittsburgh       8.426937e-07\n",
      "Portland         4.814026e-09\n",
      "San+Diego        6.666667e-01\n",
      "San+Francisco    3.700000e+00\n",
      "Seattle          1.111111e+00\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = df['above_107k']\n",
    "X = df[key_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False  True False False False False False False False False False False\n",
      " False  True False False False False False  True False False False False\n",
      " False False False False False False False False  True  True False False\n",
      " False False False False False False False False False False]\n",
      "[15  1 38 39 19 37  5 41  8 32 26 13 40  1 36 25 28 35 10  1 20 18  9 34  4\n",
      " 16 24 27 42 33  3 14  1  1 11 12 17 22 21 23 30  2 31 29  6  7]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression()\n",
    "rfe = RFE(model,5,step=1)\n",
    "rfe = rfe.fit(X,y)\n",
    "\n",
    "print(rfe.support_)\n",
    "print(rfe.ranking_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('data_scientist', 1)\n",
      "('machine_learning', 5)\n",
      "('nlp', 1)\n",
      "('c++', 1)\n",
      "('impala', 4)\n",
      "('matlab', 3)\n",
      "('spss', 1)\n",
      "('cloud', 1)\n",
      "('tableau', 2)\n"
     ]
    }
   ],
   "source": [
    "# top 5 strong features\n",
    "\n",
    "for i,j in zip(X.columns, rfe.ranking_):\n",
    "    if j < 6:\n",
    "        print (i,j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y = df['above_107k']\n",
    "X = df[['senior','junior','manager','assistant','director','associate',\n",
    "        'vp','master','phd']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('train_score:', 0.63486842105263153, 'test_score:', 0.51960784313725494)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "lr = LogisticRegression()\n",
    "model = lr.fit(X_train, y_train)\n",
    "train_score = lr.score(X_train, y_train)\n",
    "test_score = lr.score(X_test, y_test)\n",
    "\n",
    "predict = lr.predict_proba(X_test)\n",
    "print('train_score:', train_score, 'test_score:', test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "     senior       0.51      0.78      0.61        50\n",
      "     junior       0.56      0.27      0.36        52\n",
      "\n",
      "avg / total       0.53      0.52      0.49       102\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_true = y_test\n",
    "y_pred = lr.predict(X_test)\n",
    "target_names = ['senior','junior','manager','assistant','director','associate',\n",
    "                'vp','master','phd']\n",
    "\n",
    "print(classification_report(y_true, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.6097561   0.63414634  0.6097561   0.48780488  0.51219512  0.58536585\n",
      "  0.48780488  0.5         0.55        0.58974359]\n",
      "0.556657285804\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "scores = cross_val_score(knn, X, y, cv=10)\n",
    "print scores\n",
    "print np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>high_salary_prob</th>\n",
       "      <th>low_salary_prob</th>\n",
       "      <th>y_hat</th>\n",
       "      <th>y_true</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   high_salary_prob  low_salary_prob  y_hat  y_true\n",
       "0               0.2              0.8      0       0\n",
       "1               0.2              0.8      0       0\n",
       "2               0.2              0.8      0       0\n",
       "3               0.2              0.8      0       0\n",
       "4               0.2              0.8      0       0\n",
       "5               0.0              1.0      0       0\n",
       "6               0.2              0.8      0       0\n",
       "7               0.2              0.8      0       0\n",
       "8               0.2              0.8      0       0\n",
       "9               0.2              0.8      0       1"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.fit(X, y)\n",
    "predicted = knn.predict(X)\n",
    "predicted_probs = knn.predict_proba(X)\n",
    "high_salary_preds = pd.DataFrame({\n",
    "        'y_true':y,\n",
    "        'y_hat':predicted,\n",
    "        'high_salary_prob':predicted_probs[:, 1],\n",
    "        'low_salary_prob':predicted_probs[:, 0]\n",
    "    })\n",
    "\n",
    "high_salary_preds.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[214,   3],\n",
       "       [172,  17]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix \n",
    "\n",
    "confusion_matrix(y, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "     senior       0.55      0.99      0.71       217\n",
      "     junior       0.85      0.09      0.16       189\n",
      "\n",
      "avg / total       0.69      0.57      0.46       406\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target_names = ['senior','junior','manager','assistant','director','associate',\n",
    "        'vp','master','phd']\n",
    "\n",
    "print(classification_report(y, predicted, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.56896551724137934"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Accuracy: proportion of high salary correctly predicted by \n",
    "# the model\n",
    "\n",
    "accuracy_score(y, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = df['above_107k']\n",
    "X = df[key_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.82926829  0.7804878   0.70731707  0.65853659  0.75609756  0.73170732\n",
      "  0.65853659  0.575       0.95        0.84615385]\n",
      "0.749310506567\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "scores = cross_val_score(knn, X, y, cv=10)\n",
    "print scores\n",
    "print np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "knn.fit(X, y)\n",
    "predicted = knn.predict(X)\n",
    "predicted_probs = knn.predict_proba(X)\n",
    "contingency_table = pd.DataFrame(confusion_matrix(y, predicted),\n",
    "                                 columns=['Predicted 0', 'Predicted 1'],\n",
    "                                 index=['Actual 0', 'Actual 1'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted 0</th>\n",
       "      <th>Predicted 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual 0</th>\n",
       "      <td>186</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual 1</th>\n",
       "      <td>48</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Predicted 0  Predicted 1\n",
       "Actual 0          186           31\n",
       "Actual 1           48          141"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contingency_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.80541871921182262"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LassoCV, RidgeCV\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 400 candidates, totalling 4000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 4000 out of 4000 | elapsed:   38.2s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'penalty': ['l1', 'l2'], 'C': array([  1.00000e-04,   5.03508e-02, ...,   9.94975e+00,   1.00000e+01]), 'solver': ['liblinear']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=1)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "\n",
    "params = {\n",
    "    'penalty':['l1','l2'], #l1 is lasso, l2 is ridge EL-1, EL-2, NOT one-one, one-two\n",
    "    'solver':['liblinear'],\n",
    "    'C':np.linspace(0.0001, 10, 200)\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(lr, params, cv=10, verbose=1)\n",
    "gs.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.773399014778\n",
      "{'penalty': 'l2', 'C': 0.3518552763819095, 'solver': 'liblinear'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.3154704 ,  1.16743386, -0.04421938, -0.10933542,  0.27031871,\n",
       "         0.08250311,  0.48821779,  0.15014346, -0.39590325,  0.08280744,\n",
       "         0.08840517, -0.35445553, -0.01790336,  0.41438385,  0.04853779,\n",
       "         0.11302301, -0.07110818, -0.00924679,  0.2772703 ,  0.95473891,\n",
       "        -0.3023672 ,  0.14038039,  0.22506689,  0.06154385,  0.23370307,\n",
       "        -0.21801292, -0.16731417, -0.2242377 , -0.09477753, -0.00900597,\n",
       "        -0.29867827, -0.24270904, -0.47031489, -0.70729459,  0.25236385,\n",
       "        -0.22293175, -0.15023165,  0.08099666, -0.20456088,  0.14038039,\n",
       "        -0.08001636, -0.38241872,  0.09713396, -0.11537232, -0.27446443,\n",
       "         0.21235187]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print gs.best_score_\n",
    "print gs.best_params_\n",
    "gs.best_estimator_.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abscoef</th>\n",
       "      <th>coef</th>\n",
       "      <th>variable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.167434</td>\n",
       "      <td>1.167434</td>\n",
       "      <td>data_scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.954739</td>\n",
       "      <td>0.954739</td>\n",
       "      <td>c++</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.707295</td>\n",
       "      <td>-0.707295</td>\n",
       "      <td>cloud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.488218</td>\n",
       "      <td>0.488218</td>\n",
       "      <td>machine_learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.470315</td>\n",
       "      <td>-0.470315</td>\n",
       "      <td>spss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.414384</td>\n",
       "      <td>0.414384</td>\n",
       "      <td>nlp</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     abscoef      coef          variable\n",
       "1   1.167434  1.167434    data_scientist\n",
       "19  0.954739  0.954739               c++\n",
       "33  0.707295 -0.707295             cloud\n",
       "6   0.488218  0.488218  machine_learning\n",
       "32  0.470315 -0.470315              spss\n",
       "13  0.414384  0.414384               nlp"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coefs_vars = pd.DataFrame({\n",
    "        'coef':gs.best_estimator_.coef_[0],\n",
    "        'variable':X.columns,\n",
    "        'abscoef':np.abs(gs.best_estimator_.coef_[0])\n",
    "    })\n",
    "coefs_vars.sort_values('abscoef', ascending=False, inplace=True)\n",
    "coefs_vars[coefs_vars.coef != 0].head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 20 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    5.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise',\n",
       "       estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform'),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'n_neighbors': [1, 3, 5, 7, 9, 11, 13, 15, 17, 19], 'weights': ['uniform', 'distance']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=1)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "knn_params = {\n",
    "    'n_neighbors':range(1,20,2),\n",
    "    'weights':['uniform','distance']\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(knn, knn_params, cv=10, verbose=1)\n",
    "gs.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.770935960591\n",
      "{'n_neighbors': 9, 'weights': 'uniform'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print gs.best_score_\n",
    "print gs.best_params_\n",
    "gs.best_estimator_.n_neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CountVectorizer()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
